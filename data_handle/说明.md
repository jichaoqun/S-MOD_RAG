# 数据处理说明
数据处理分为四部分：
1. 原始数据读取，包括：txt、json、csv、pdf等格式
2. 数据清洗，去除数据中的噪声和冗余信息
3. 数据切分，将数据按照句子（最常见）、段落、实体关系等方式进行切分
4. 数据存储，使用关系型数据库直接存储且分好的数据，在大规模数据中我认为这部分直接存在向量数据库中也没有问题，这里只是为了能可视化查看切分后的数据。

## 数据切分
数据的切分方式直接决定了后续query的召回质量，切分方式也没有绝对的好坏之说，虽然知识图谱类的知识库能够检索到的相关知识是最好的，但构建知识图谱就是一个很难的事情；句子与段落的方式，在绝大部分的任务中都已经能胜任，除去那些很明确的特定的关系数据（我认为那些数据完全可以使用规则判断来更精准的控制）。
*固定长度切分,在这里不进行讨论*
1. 句子级别切分
>在RAG常用的数据切分中，句子切分是最常用的，也基本能满足基本的任务
>**优点**：简单，容易实现，只需要按照句子的句号进行切分即可，假如超过长度需要注意句子之间的重叠，保持句子意思的完整性；
>**缺点**：切分后的数据质量不高，容易丢失一些重要的信息，比如一些长句，或者一些长段落，这些信息在句子级别切分中很难保留下来，缺失了数据的完整性。
2. 段落级别切分
>段落级别切分，在句子级别切分的基础上，将句子按照段落进行切分；
>**优点**：可以保留更多的句子完整信息。
>**缺点**：缺少细节信息，并且字啊进行向量化的时候还需要考虑embedding模型的能力。
3. 实体关系切分
>抽取句子中的三元组或实体之间的更精细的关系，为构建知识图谱做准备
>**优点**：实体或者有用知识块之间的逻辑关系更明确，能够提供更精细的查找；知识图谱的构建本身就可以看成一个attention的计算；
>**缺点**：知识图谱的构建很复杂，特别是对没有很强的逻辑关系文本，解析这些文本可能需要更长的上下文或是全局的判断，其次，实体之间的关系定义也比较难，没有一个规定的范式。

